experiment:
  name: "baseline_experiment"
  seed: 42
  device: "cpu"         # or "cuda"
  rounds: 5
  batch_size: 128
  lr: 0.001
  optimizer: "adam"
  strategies: ["FedAvg", "FedProx", "PersonalizedHead"]
  strategy: "FedAvg"
  equalize_samples: true
  reweight_clients: false
  fedprox_mu: 0.001
  local_epochs: 3
  early_stopping_patience: 2
  max_train_samples_per_client: 50000

data:
  raw_dir: "data/raw_data"
  processed_dir: "data/processed"
  # We now KNOW the schema. We'll ignore auto-detect and enforce these:
  label_column: "Label"
  drop_columns:
    - "timestamp"
    - "unique_id"
    - "orig_host"
    - "orig_port"
    - "resp_host"
    - "resp_port"
    - "tunnel_parents"
    - "Sub_Label"      # we drop it after counting it
  numeric_features:
    - "duration"
    - "orig_bytes"
    - "resp_bytes"
  categorical_features:
    - "protocol"
    - "service"
    - "conn_state"
    - "local_orig"
    - "local_resp"
    - "history"
  test_size: 0.2
  random_state: 42

preprocess:
  scaler: "standard"     # "standard" or "minmax"
  use_smote: true
  smote_minority_ratio_threshold: 0.3

logging:
  log_level: "INFO"

evaluation:
  fairness_metrics: true
  save_plots: true

output:
  results_dir: "results"
  logs_dir: "results/logs"
  summaries_dir: "results/summaries"
  artifacts_dir: "results/artifacts"
